{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read files\n",
    "\n",
    "with open('interbrand_brand2rankvalue.json') as f:\n",
    "    brand_ranking = json.load(f)\n",
    "    \n",
    "with open('google_trends.json') as f:\n",
    "    google_trends = json.load(f)\n",
    "\n",
    "data = []\n",
    "\n",
    "for brand, interest in google_trends.items():\n",
    "    for year in range(2009, 2020):\n",
    "        rank = brand_ranking[brand].get(str(year), [101])[0]\n",
    "        data.append([brand, int(year), rank, interest[str(year-1)], interest[str(year-2)], interest[str(year-3)], interest[str(year-4)], interest[str(year-5)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>year</th>\n",
       "      <th>rank(t)</th>\n",
       "      <th>google(t-1)</th>\n",
       "      <th>google(t-2)</th>\n",
       "      <th>google(t-3)</th>\n",
       "      <th>google(t-4)</th>\n",
       "      <th>google(t-5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cocacola</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>56.083333</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>61.750000</td>\n",
       "      <td>68.583333</td>\n",
       "      <td>56.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cocacola</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>56.083333</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>61.750000</td>\n",
       "      <td>68.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cocacola</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>31.833333</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>56.083333</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>61.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cocacola</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>31.833333</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>56.083333</td>\n",
       "      <td>63.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cocacola</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>31.833333</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>56.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>linkedin</td>\n",
       "      <td>2015</td>\n",
       "      <td>101</td>\n",
       "      <td>89.666667</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>71.416667</td>\n",
       "      <td>54.500000</td>\n",
       "      <td>30.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>linkedin</td>\n",
       "      <td>2016</td>\n",
       "      <td>101</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>89.666667</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>71.416667</td>\n",
       "      <td>54.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>linkedin</td>\n",
       "      <td>2017</td>\n",
       "      <td>101</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>89.666667</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>71.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>linkedin</td>\n",
       "      <td>2018</td>\n",
       "      <td>101</td>\n",
       "      <td>74.583333</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>89.666667</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>linkedin</td>\n",
       "      <td>2019</td>\n",
       "      <td>98</td>\n",
       "      <td>70.500000</td>\n",
       "      <td>74.583333</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>89.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1903 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         brand  year  rank(t)  google(t-1)  google(t-2)  google(t-3)  \\\n",
       "0     cocacola  2009        1    56.083333    63.750000    61.750000   \n",
       "1     cocacola  2010        1    37.000000    56.083333    63.750000   \n",
       "2     cocacola  2011        1    31.833333    37.000000    56.083333   \n",
       "3     cocacola  2012        1    31.750000    31.833333    37.000000   \n",
       "4     cocacola  2013        3    30.750000    31.750000    31.833333   \n",
       "...        ...   ...      ...          ...          ...          ...   \n",
       "1898  linkedin  2015      101    89.666667    89.000000    71.416667   \n",
       "1899  linkedin  2016      101    95.500000    89.666667    89.000000   \n",
       "1900  linkedin  2017      101    82.500000    95.500000    89.666667   \n",
       "1901  linkedin  2018      101    74.583333    82.500000    95.500000   \n",
       "1902  linkedin  2019       98    70.500000    74.583333    82.500000   \n",
       "\n",
       "      google(t-4)  google(t-5)  \n",
       "0       68.583333    56.416667  \n",
       "1       61.750000    68.583333  \n",
       "2       63.750000    61.750000  \n",
       "3       56.083333    63.750000  \n",
       "4       37.000000    56.083333  \n",
       "...           ...          ...  \n",
       "1898    54.500000    30.416667  \n",
       "1899    71.416667    54.500000  \n",
       "1900    89.000000    71.416667  \n",
       "1901    89.666667    89.000000  \n",
       "1902    95.500000    89.666667  \n",
       "\n",
       "[1903 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "df = pd.DataFrame(data, columns=['brand', 'year', 'rank(t)', 'google(t-1)', 'google(t-2)', 'google(t-3)', 'google(t-4)', 'google(t-5)'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training data split\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "train_test_split(df[['google(t-1)', 'google(t-2)', 'google(t-3)', 'google(t-4)', 'google(t-5)']], df['rank(t)'], test_size=0.25, random_state=12580)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024168076418064288"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "pred_train = model.predict(x_train)\n",
    "r2_score(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>rank(t)</td>     <th>  R-squared:         </th> <td>   0.024</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.021</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   7.039</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 10 Dec 2020</td> <th>  Prob (F-statistic):</th> <td>1.65e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:46:38</td>     <th>  Log-Likelihood:    </th> <td> -7014.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1427</td>      <th>  AIC:               </th> <td>1.404e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1421</td>      <th>  BIC:               </th> <td>1.407e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td>   83.2592</td> <td>    2.215</td> <td>   37.585</td> <td> 0.000</td> <td>   78.914</td> <td>   87.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>google(t-1)</th> <td>   -0.2485</td> <td>    0.161</td> <td>   -1.539</td> <td> 0.124</td> <td>   -0.565</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>google(t-2)</th> <td>    0.2872</td> <td>    0.277</td> <td>    1.036</td> <td> 0.300</td> <td>   -0.257</td> <td>    0.831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>google(t-3)</th> <td>   -0.1618</td> <td>    0.294</td> <td>   -0.550</td> <td> 0.583</td> <td>   -0.739</td> <td>    0.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>google(t-4)</th> <td>    0.1464</td> <td>    0.302</td> <td>    0.485</td> <td> 0.628</td> <td>   -0.445</td> <td>    0.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>google(t-5)</th> <td>   -0.2566</td> <td>    0.169</td> <td>   -1.522</td> <td> 0.128</td> <td>   -0.587</td> <td>    0.074</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>260.172</td> <th>  Durbin-Watson:     </th> <td>   2.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 165.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.713</td>  <th>  Prob(JB):          </th> <td>1.17e-36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.134</td>  <th>  Cond. No.          </th> <td>    312.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                rank(t)   R-squared:                       0.024\n",
       "Model:                            OLS   Adj. R-squared:                  0.021\n",
       "Method:                 Least Squares   F-statistic:                     7.039\n",
       "Date:                Thu, 10 Dec 2020   Prob (F-statistic):           1.65e-06\n",
       "Time:                        19:46:38   Log-Likelihood:                -7014.9\n",
       "No. Observations:                1427   AIC:                         1.404e+04\n",
       "Df Residuals:                    1421   BIC:                         1.407e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const          83.2592      2.215     37.585      0.000      78.914      87.605\n",
       "google(t-1)    -0.2485      0.161     -1.539      0.124      -0.565       0.068\n",
       "google(t-2)     0.2872      0.277      1.036      0.300      -0.257       0.831\n",
       "google(t-3)    -0.1618      0.294     -0.550      0.583      -0.739       0.416\n",
       "google(t-4)     0.1464      0.302      0.485      0.628      -0.445       0.738\n",
       "google(t-5)    -0.2566      0.169     -1.522      0.128      -0.587       0.074\n",
       "==============================================================================\n",
       "Omnibus:                      260.172   Durbin-Watson:                   2.019\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              165.469\n",
       "Skew:                          -0.713   Prob(JB):                     1.17e-36\n",
       "Kurtosis:                       2.134   Cond. No.                         312.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.api import OLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "x_train = sm.add_constant(x_train)\n",
    "model = OLS(y_train, x_train).fit()\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
